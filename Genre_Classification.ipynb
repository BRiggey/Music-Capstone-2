{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Acknowledgment:\n",
    "# This code was developed with assistance from ChatGPT, which provided initial guidance\n",
    "# and code snippets. Significant modifications and improvements were made by us to \n",
    "# ensure the code meets the specific requirements of the project. All optimizations \n",
    "# and final adjustments were implemented independently.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Usual Libraries USED FROM THE OTHER NOTEBOOK WE ADD MORE OR DELETE WHEN NECESSESARRY \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import distutils\n",
    "import ast\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing TFRecord Data and Extracting Features\n",
    "\n",
    "This code demonstrates how to parse TFRecord files containing audio embeddings and associated labels, transforming them into a DataFrame for further analysis or model training.\n",
    "\n",
    "### Code Overview:\n",
    "\n",
    "- **Context Features**: Metadata like video ID and timestamps.\n",
    "- **Sequence Features**: The audio embeddings, stored as variable-length sequences.\n",
    "- **Normalization**: The audio embeddings are reshaped and normalized for training.\n",
    "- **DataFrame Creation**: Collects parsed data and stores it in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the context features\n",
    "context_features = {\n",
    "    'video_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'start_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'end_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'labels': tf.io.VarLenFeature(tf.int64)\n",
    "}\n",
    "\n",
    "# Define the sequence features\n",
    "sequence_features = {\n",
    "    'audio_embedding': tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the example into context and sequence features\n",
    "    context_data, sequence_data = tf.io.parse_single_sequence_example(\n",
    "        example_proto,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    \n",
    "    # Decode the audio embeddings from the byte strings\n",
    "    audio_embeddings = tf.io.decode_raw(sequence_data['audio_embedding'].values, tf.uint8)\n",
    "    \n",
    "    # Check the shape of audio_embeddings and calculate the appropriate reshape\n",
    "    audio_embeddings = tf.reshape(audio_embeddings, [-1, 128])  # Modify as necessary based on your data\n",
    "    \n",
    "    # Normalize the embeddings to the range [0, 1]\n",
    "    audio_embeddings = tf.cast(audio_embeddings, tf.float32) / 255.0\n",
    "    \n",
    "    # Return the 2D reshaped embeddings\n",
    "    labels = tf.sparse.to_dense(context_data['labels'])\n",
    "    \n",
    "    return audio_embeddings, labels  # Return the embeddings as 2D arrays\n",
    "\n",
    "\n",
    "\n",
    "def parse_tfrecords_to_dataframe(tfrecord_files):\n",
    "    # Initialize an empty list to store embeddings and labels\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate through each TFRecord file in the folder\n",
    "    for tfrecord_file in tqdm(tfrecord_files, desc=\"Processing TFRecord files\"):\n",
    "        raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "        parsed_dataset = raw_dataset.map(_parse_function)\n",
    "\n",
    "        # Iterate over the parsed dataset and collect embeddings and labels\n",
    "        for audio_embedding, labels in parsed_dataset:\n",
    "            # Convert to numpy arrays\n",
    "            audio_embedding_np = audio_embedding.numpy()\n",
    "            labels_np = labels.numpy()\n",
    "\n",
    "            # Flatten the label array if necessary\n",
    "            labels_np = labels_np.flatten() if len(labels_np.shape) > 0 else labels_np\n",
    "\n",
    "            # Store the embedding and label\n",
    "            embeddings_list.append(audio_embedding_np)\n",
    "            labels_list.append(labels_np)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame({\n",
    "        'embedding': embeddings_list,\n",
    "        'labels': labels_list\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Specify the folder containing TFRecord files\n",
    "bal_tfrecord_folder = '.github\\Data\\\\bal_train'\n",
    "bal_tfrecord_files = [os.path.join(bal_tfrecord_folder, f) for f in os.listdir(bal_tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "\n",
    "eval_tfrecord_folder = '.github\\Data\\\\eval'\n",
    "eval_tfrecord_files = [os.path.join(eval_tfrecord_folder, f) for f in os.listdir(eval_tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "eval_df = parse_tfrecords_to_dataframe(eval_tfrecord_files)\n",
    "# Parse the TFRecords into a DataFrame\n",
    "bal_df = parse_tfrecords_to_dataframe(bal_tfrecord_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Save DataFrames to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'data' directory exists\n",
    "output_folder = r'.github\\Data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Paths for saving the CSV files\n",
    "eval_csv_path = os.path.join(output_folder, 'eval_df.csv')\n",
    "bal_csv_path = os.path.join(output_folder, 'bal_df.csv')\n",
    "\n",
    "# Save the DataFrames to CSV\n",
    "eval_df.to_csv(eval_csv_path, index=False)\n",
    "bal_df.to_csv(bal_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Clean Invalid Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop invalid embeddings based on shape\n",
    "def drop_invalid_embeddings(df):\n",
    "    valid_entries = []\n",
    "    \n",
    "    for i, emb in enumerate(df['embedding']):\n",
    "        emb_array = np.array(emb)\n",
    "        if emb_array.shape == (10, 128):  # Only keep valid embeddings\n",
    "            valid_entries.append(i)\n",
    "    \n",
    "    return df.iloc[valid_entries]\n",
    "\n",
    "# Drop invalid entries from the training set\n",
    "bal_df_clean = drop_invalid_embeddings(bal_df)\n",
    "\n",
    "eval_df_clean = drop_invalid_embeddings(eval_df)\n",
    "\n",
    "# Check the cleaned DataFrame\n",
    "print(f\"Cleaned training set shape: {bal_df_clean.shape}\")\n",
    "print(f\"Cleaned test set shape: {eval_df_clean.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Binarization and Data Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Convert multi-labels to binary format (one-hot encoding)\n",
    "y_train = mlb.fit_transform(bal_df_clean['labels'])\n",
    "y_test = mlb.transform(eval_df_clean['labels'])\n",
    "\n",
    "\n",
    "X_train = np.array(bal_df_clean['embedding'].tolist()).reshape(-1, 10, 128, 1)\n",
    "X_test = np.array(eval_df_clean['embedding'].tolist()).reshape(-1, 10, 128, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major Key Profiles for Music Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 means the notes is apart of the scale, and 0 means that it is not\n",
    "# The twelve major scales are C C# D D# E F F# G G# A A# B\n",
    "# EX. C major scale is C D E F G A B which is the first scale in the array\n",
    "MAJOR_KEY_PROFILES = np.array([\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1],  # C Major\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0],  # C# Major\n",
    "    [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],  # D Major\n",
    "    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],  # Eb Major\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],  # E Major\n",
    "    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],  # F Major\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],  # F# Major\n",
    "    [1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0],  # G Major\n",
    "    [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],  # Ab Major\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],  # A Major\n",
    "    [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],  # Bb Major\n",
    "    [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0],  # B Major\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Key Detection Using Chroma Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "#https://cs229.stanford.edu/proj2016/report/Mahieu-DetectingMusicalKeyWithSupervisedLearning-report.pdf\n",
    "#https://www.kaggle.com/discussions/general/278766 \n",
    "#https://librosa.org/doc/main/generated/librosa.feature.chroma_cqt.html\n",
    "\n",
    "\n",
    "\n",
    "def probabilistic_key_detection(chroma_profile, key_profiles):\n",
    "    \"\"\"\n",
    "    Detects the most likely key using a probabilistic approach.\n",
    "    \n",
    "    Args:\n",
    "        chroma_profile (np.array): A 12-dimensional chroma vector (normalized).\n",
    "        key_profiles (np.array): A 12x12 matrix of major key templates.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted key name.\n",
    "    \"\"\"\n",
    "    # make the sum of all the elements = 1 for consistency \n",
    "    chroma_profile = chroma_profile / np.sum(chroma_profile)\n",
    "\n",
    "    likelihoods = []\n",
    "    for key_profile in key_profiles:\n",
    "        # Compute the likelihood by using a guassian noramlization method\n",
    "        # It finds the difference in squares, and then uses a guassian equation to find the likelihood of the key. \n",
    "        likelihood = np.exp(-0.5 * np.sum((chroma_profile - key_profile) ** 2))\n",
    "        likelihoods.append(likelihood)\n",
    "    \n",
    "    # The sum of all probabilities will = 1, so that we can later find the highest probabability key\n",
    "    likelihoods = np.array(likelihoods)\n",
    "    likelihoods /= np.sum(likelihoods)\n",
    "\n",
    "    # Identify the most probable key\n",
    "    keys = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "    # Assigns the highest value likelyhoods of the keys \n",
    "    most_likely_key = keys[np.argmax(likelihoods)]\n",
    "    \n",
    "    return most_likely_key, likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma Feature Extraction from Audio Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "def extract_chroma_features(audio_embedding, sr=22050):\n",
    "    \"\"\"\n",
    "    Extracts chroma features from an audio embedding.\n",
    "    \n",
    "    Args:\n",
    "        audio_embedding (np.array): Flattened audio embedding representing a segment.\n",
    "        sr (int): Sampling rate (default is 22050).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Normalized 12-dimensional chroma feature.\n",
    "    \"\"\"\n",
    "    # Ensure embedding is in range [-1, 1] as librosa expects audio signals\n",
    "    audio_embedding = audio_embedding / np.max(np.abs(audio_embedding))\n",
    "\n",
    "    # Extract chroma features using librosa\n",
    "    chroma = librosa.feature.chroma_cqt(y=audio_embedding, sr=sr, n_chroma=12)\n",
    "\n",
    "    # Average across time steps to get a single 12-dimensional vector\n",
    "    chroma_avg = np.mean(chroma, axis=1)\n",
    "\n",
    "    # Normalize the chroma profile to sum to 1\n",
    "    chroma_normalized = chroma_avg / np.sum(chroma_avg)\n",
    "\n",
    "    return chroma_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Key Prediction for Dataset Using Probabilistic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `probabilistic_key_detection()` function and `MAJOR_KEY_PROFILES` are defined\n",
    "\n",
    "# Generate key predictions for the dataset\n",
    "bal_key_predictions = []\n",
    "for index, row in bal_df_clean.iterrows():\n",
    "    # Extract audio embedding\n",
    "    audio_embedding = np.array(row['embedding'])  # Ensure the embedding is a numpy array\n",
    "\n",
    "    # Extract chroma features from the embedding\n",
    "    chroma_profile = extract_chroma_features(audio_embedding)\n",
    "\n",
    "    # Detect the most likely key and its likelihood distribution\n",
    "    predicted_key, _ = probabilistic_key_detection(chroma_profile, MAJOR_KEY_PROFILES)\n",
    "\n",
    "    # Store the predicted key\n",
    "    bal_key_predictions.append(predicted_key)\n",
    "\n",
    "# Add predicted keys to the dataframe\n",
    "bal_df_clean['predicted_key'] = bal_key_predictions\n",
    "print('bal Done')\n",
    "eval_key_predictions = []\n",
    "for index, row in eval_df_clean.iterrows():\n",
    "    # Extract audio embedding\n",
    "    audio_embedding = np.array(row['embedding'])  # Ensure the embedding is a numpy array\n",
    "\n",
    "    # Extract chroma features from the embedding\n",
    "    chroma_profile = extract_chroma_features(audio_embedding)\n",
    "\n",
    "    # Detect the most likely key and its likelihood distribution\n",
    "    predicted_key, _ = probabilistic_key_detection(chroma_profile, MAJOR_KEY_PROFILES)\n",
    "\n",
    "    # Store the predicted key\n",
    "    eval_key_predictions.append(predicted_key)\n",
    "eval_df_clean['predicted_key'] = eval_key_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding and Data Preprocessing for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Label encode the predicted keys (for training data)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(bal_df_clean['predicted_key'])\n",
    "\n",
    "# Reshape the embedding for CNN input (ensure correct dimensions)\n",
    "X_train = np.array(bal_df_clean['embedding'].tolist()).reshape(-1, 10, 128, 1)\n",
    "\n",
    "# For test data, use the same LabelEncoder instance (do not fit again)\n",
    "y_test = le.transform(eval_df_clean['predicted_key'])  # Using transform, not fit_transform\n",
    "X_test = np.array(eval_df_clean['embedding'].tolist()).reshape(-1, 10, 128, 1)\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Architecture for Key Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(10, 128, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the results of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(le.classes_), activation='softmax'))  # For multi-class classification\n",
    "optimizer = Adam(learning_rate= 0.0001)\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "# Summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training for Key Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train_one_hot, epochs=10, batch_size=32, validation_data=(X_test, y_test_one_hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Class Distribution in Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_train is the target variable (the true labels)\n",
    "# If y_train is encoded as integers, you can directly use the following code\n",
    "\n",
    "# Count the frequency of each class\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "import pandas as pd\n",
    "class_distribution = pd.DataFrame({'Class': unique, 'Frequency': counts})\n",
    "\n",
    "# Sort the class distribution by class label\n",
    "class_distribution = class_distribution.sort_values(by='Class')\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Class', y='Frequency', data=class_distribution, palette='viridis')\n",
    "plt.title('Class Distribution in Training Set')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model with Enhanced Layers and Early Stopping for Multi-Label Classification for Genre Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the CNN model with enhancements\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional Layer 1 with padding and increased filters\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    # Convolutional Layer 2 with padding and increased filters\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    # Convolutional Layer 3 with padding and increased filters\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    # Global Average Pooling\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # Fully connected layer with dropout\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout to reduce overfitting\n",
    "\n",
    "    # Output layer for multi-label classification\n",
    "    model.add(layers.Dense(num_classes, activation='sigmoid'))  # Sigmoid for multi-label\n",
    "\n",
    "    return model\n",
    "\n",
    "# Set input shape and number of classes (labels)\n",
    "input_shape = (10, 128, 1)  # Shape of each input sample (10, 128, 1)\n",
    "num_classes = y_train.shape[1]  # Number of unique labels\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=Adam(learning_rate=0.001),  # Use a lower learning rate\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "cnn_model.summary()\n",
    "\n",
    "# Train the model with early stopping to avoid overfitting\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "cnn_model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Training and Validation Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training history\n",
    "history = cnn_model.history.history\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
