{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Acknowledgment:\n",
    "# This code was developed with assistance from ChatGPT, which provided initial guidance\n",
    "# and code snippets. Significant modifications and improvements were made by me to \n",
    "# ensure the code meets the specific requirements of the project. All optimizations \n",
    "# and final adjustments were implemented independently.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Usual Libraries USED FROM THE OTHER NOTEBOOK WE ADD MORE OR DELETE WHEN NECESSESARRY \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import distutils\n",
    "import ast\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing TFRecord files: 100%|██████████| 1444/1444 [01:32<00:00, 15.64it/s]\n",
      "Processing TFRecord files: 100%|██████████| 1444/1444 [01:30<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the context features\n",
    "context_features = {\n",
    "    'video_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'start_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'end_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'labels': tf.io.VarLenFeature(tf.int64)\n",
    "}\n",
    "\n",
    "# Define the sequence features\n",
    "sequence_features = {\n",
    "    'audio_embedding': tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the example into context and sequence features\n",
    "    context_data, sequence_data = tf.io.parse_single_sequence_example(\n",
    "        example_proto,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    \n",
    "    # Decode the audio embeddings from the byte strings\n",
    "    audio_embeddings = tf.io.decode_raw(sequence_data['audio_embedding'].values, tf.uint8)\n",
    "    audio_embeddings = tf.reshape(audio_embeddings, [-1, 128])  # Reshape to [time_steps, embedding_size]\n",
    "    \n",
    "    # Normalize the embeddings to the range [0, 1]\n",
    "    audio_embeddings = tf.cast(audio_embeddings, tf.float32) / 255.0\n",
    "    \n",
    "    # Flatten the embedding to a 1D array\n",
    "    flattened_embedding = tf.reshape(audio_embeddings, [-1])\n",
    "    \n",
    "    # Convert sparse labels to dense\n",
    "    labels = tf.sparse.to_dense(context_data['labels'])\n",
    "    \n",
    "    return flattened_embedding, labels\n",
    "\n",
    "def parse_tfrecords_to_dataframe(tfrecord_files):\n",
    "    # Initialize an empty list to store embeddings and labels\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate through each TFRecord file in the folder\n",
    "    for tfrecord_file in tqdm(tfrecord_files, desc=\"Processing TFRecord files\"):\n",
    "        raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "        parsed_dataset = raw_dataset.map(_parse_function)\n",
    "\n",
    "        # Iterate over the parsed dataset and collect embeddings and labels\n",
    "        for audio_embedding, labels in parsed_dataset:\n",
    "            # Convert to numpy arrays\n",
    "            audio_embedding_np = audio_embedding.numpy()\n",
    "            labels_np = labels.numpy()\n",
    "\n",
    "            # Flatten the label array if necessary\n",
    "            labels_np = labels_np.flatten() if len(labels_np.shape) > 0 else labels_np\n",
    "\n",
    "            # Store the embedding and label\n",
    "            embeddings_list.append(audio_embedding_np)\n",
    "            labels_list.append(labels_np)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame({\n",
    "        'embedding': embeddings_list,\n",
    "        'labels': labels_list\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Specify the folder containing TFRecord files\n",
    "bal_tfrecord_folder = '.github\\Data\\\\bal_train'\n",
    "bal_tfrecord_files = [os.path.join(bal_tfrecord_folder, f) for f in os.listdir(bal_tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "\n",
    "eval_tfrecord_folder = '.github\\Data\\\\eval'\n",
    "eval_tfrecord_files = [os.path.join(eval_tfrecord_folder, f) for f in os.listdir(eval_tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "eval_df = parse_tfrecords_to_dataframe(eval_tfrecord_files)\n",
    "# Parse the TFRecords into a DataFrame\n",
    "bal_df = parse_tfrecords_to_dataframe(bal_tfrecord_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'data' directory exists\n",
    "output_folder = r'.github\\Data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Paths for saving the CSV files\n",
    "eval_csv_path = os.path.join(output_folder, 'eval_df.csv')\n",
    "bal_csv_path = os.path.join(output_folder, 'bal_df.csv')\n",
    "\n",
    "# Save the DataFrames to CSV\n",
    "eval_df.to_csv(eval_csv_path, index=False)\n",
    "bal_df.to_csv(bal_csv_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape them  embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Embeddings Shape: (7971, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "# Parameters (adjust as necessary)\n",
    "embedding_length = 128  # This should match the original dimension of each heatmap slice\n",
    "sequence_length = 100  # Adjust to match the desired number of time steps per sequence\n",
    "\n",
    "# Convert the embedding column to a numpy array and reshape each embedding\n",
    "def reshape_embeddings(df, embedding_length, sequence_length):\n",
    "    reshaped_embeddings = []\n",
    "    for embedding in df['embedding']:\n",
    "        # Ensure embedding is a numpy array\n",
    "        embedding = np.array(embedding)\n",
    "        \n",
    "        # Reshape the embedding into (sequence_length, embedding_length)\n",
    "        # If necessary, truncate or pad to the sequence_length\n",
    "        if len(embedding) < sequence_length * embedding_length:\n",
    "            # Pad with zeros if too short\n",
    "            padding_length = sequence_length * embedding_length - len(embedding)\n",
    "            embedding = np.pad(embedding, (0, padding_length), mode='constant')\n",
    "        elif len(embedding) > sequence_length * embedding_length:\n",
    "            # Truncate if too long\n",
    "            embedding = embedding[:sequence_length * embedding_length]\n",
    "        \n",
    "        # Reshape to (sequence_length, embedding_length)\n",
    "        embedding = embedding.reshape((sequence_length, embedding_length))\n",
    "        reshaped_embeddings.append(embedding)\n",
    "\n",
    "    # Convert to numpy array for model input\n",
    "    reshaped_embeddings = np.array(reshaped_embeddings)\n",
    "    return reshaped_embeddings\n",
    "\n",
    "# Apply reshaping to embeddings\n",
    "reshaped_bal_embeddings = reshape_embeddings(bal_df, embedding_length, sequence_length)\n",
    "#reshaped_eval_embeddings = reshape_embeddings(eval_df, embedding_length, sequence_length)\n",
    "# Output the reshaped array's shape to verify\n",
    "print(\"Reshaped Embeddings Shape:\", reshaped_bal_embeddings.shape)\n",
    "#print(\"Reshaped Embeddings Shape:\", reshaped_eval_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 means the notes is apart of the scale, and 0 means that it is not\n",
    "# The twelve major scales are C C# D D# E F F# G G# A A# B\n",
    "# EX. C major scale is C D E F G A B which is the first scale in the array\n",
    "MAJOR_KEY_PROFILES = np.array([\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1],  # C Major\n",
    "    [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0],  # C# Major\n",
    "    [0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],  # D Major\n",
    "    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],  # Eb Major\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],  # E Major\n",
    "    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],  # F Major\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1],  # F# Major\n",
    "    [1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0],  # G Major\n",
    "    [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],  # Ab Major\n",
    "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],  # A Major\n",
    "    [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1],  # Bb Major\n",
    "    [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0],  # B Major\n",
    "])\n",
    "\n",
    "def determine_key(chroma_aggregate):\n",
    "    # Normalize the chroma vector\n",
    "    chroma_aggregate = chroma_aggregate / np.linalg.norm(chroma_aggregate)\n",
    "\n",
    "    # Compute similarity with each major key profile\n",
    "    similarities = [np.dot(chroma_aggregate, profile) for profile in MAJOR_KEY_PROFILES]\n",
    "    \n",
    "    # Find the key with the highest similarity\n",
    "    key_index = np.argmax(similarities)\n",
    "    keys = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    return keys[key_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "#https://cs229.stanford.edu/proj2016/report/Mahieu-DetectingMusicalKeyWithSupervisedLearning-report.pdf\n",
    "#https://www.kaggle.com/discussions/general/278766\n",
    "\n",
    "\n",
    "\n",
    "def probabilistic_key_detection(chroma_profile, key_profiles):\n",
    "    \"\"\"\n",
    "    Detects the most likely key using a probabilistic approach.\n",
    "    \n",
    "    Args:\n",
    "        chroma_profile (np.array): A 12-dimensional chroma vector (normalized).\n",
    "        key_profiles (np.array): A 12x12 matrix of major key templates.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted key name.\n",
    "    \"\"\"\n",
    "    # make the sum of all the elements = 1 for consistency \n",
    "    chroma_profile = chroma_profile / np.sum(chroma_profile)\n",
    "\n",
    "    likelihoods = []\n",
    "    for key_profile in key_profiles:\n",
    "        # Compute the likelihood by using a guassian noramlization method\n",
    "        # It find the difference in squares, and then uses a guassian equation to find the likelihood of the key. \n",
    "        likelihood = np.exp(-0.5 * np.sum((chroma_profile - key_profile) ** 2))\n",
    "        likelihoods.append(likelihood)\n",
    "    \n",
    "    # The sum of all probabilities will = 1, so that we can later find the highest probabability key\n",
    "    likelihoods = np.array(likelihoods)\n",
    "    likelihoods /= np.sum(likelihoods)\n",
    "\n",
    "    # Identify the most probable key\n",
    "    keys = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "    # Assigns the highest value likelyhoods of the keys \n",
    "    most_likely_key = keys[np.argmax(likelihoods)]\n",
    "    \n",
    "    return most_likely_key, likelihoods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "def extract_chroma_features(audio_embedding, sr=22050):\n",
    "    \"\"\"\n",
    "    Extracts chroma features from an audio embedding.\n",
    "    \n",
    "    Args:\n",
    "        audio_embedding (np.array): Flattened audio embedding representing a segment.\n",
    "        sr (int): Sampling rate (default is 22050).\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Normalized 12-dimensional chroma feature.\n",
    "    \"\"\"\n",
    "    # Ensure embedding is in range [-1, 1] as librosa expects audio signals\n",
    "    audio_embedding = audio_embedding / np.max(np.abs(audio_embedding))\n",
    "\n",
    "    # Extract chroma features using librosa\n",
    "    chroma = librosa.feature.chroma_cqt(y=audio_embedding, sr=sr, n_chroma=12)\n",
    "\n",
    "    # Average across time steps to get a single 12-dimensional vector\n",
    "    chroma_avg = np.mean(chroma, axis=1)\n",
    "\n",
    "    # Normalize the chroma profile to sum to 1\n",
    "    chroma_normalized = chroma_avg / np.sum(chroma_avg)\n",
    "\n",
    "    return chroma_normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           embedding predicted_key  \\\n",
      "0  [0.37254903, 0.47843137, 0.5764706, 0.05490196...             A   \n",
      "1  [0.3137255, 0.70980394, 0.84705883, 0.6431373,...             A   \n",
      "2  [0.41960785, 0.5882353, 0.34901962, 0.5411765,...             A   \n",
      "3  [0.5529412, 0.3254902, 0.43137255, 0.69411767,...             F   \n",
      "4  [0.4, 0.18431373, 0.6666667, 0.23137255, 0.533...             A   \n",
      "\n",
      "                                         likelihoods  \n",
      "0  [0.05636778845112223, 0.08669995534079632, 0.0...  \n",
      "1  [0.056948113012707996, 0.08381732069689841, 0....  \n",
      "2  [0.05644942824928668, 0.08634687890280632, 0.0...  \n",
      "3  [0.05771204558336973, 0.08250187840304446, 0.0...  \n",
      "4  [0.056701312957757065, 0.0845041332789606, 0.0...  \n"
     ]
    }
   ],
   "source": [
    "# Example: Iterate through your dataframe and process each embedding\n",
    "key_predictions = []\n",
    "likelihood_distributions = []\n",
    "\n",
    "for index, row in bal_df.iterrows():\n",
    "    # Extract audio embedding\n",
    "    audio_embedding = np.array(row['embedding'])  # Ensure the embedding is a numpy array\n",
    "\n",
    "    # Extract chroma features from the embedding\n",
    "    chroma_profile = extract_chroma_features(audio_embedding)\n",
    "\n",
    "    # Detect the most likely key and its likelihood distribution\n",
    "    predicted_key, likelihoods = probabilistic_key_detection(chroma_profile, MAJOR_KEY_PROFILES)\n",
    "\n",
    "    # Store results\n",
    "    key_predictions.append(predicted_key)\n",
    "    likelihood_distributions.append(likelihoods)\n",
    "\n",
    "# Add the predicted keys and likelihoods to the dataframe\n",
    "bal_df['predicted_key'] = key_predictions\n",
    "bal_df['likelihoods'] = likelihood_distributions\n",
    "\n",
    "# Example output\n",
    "print(bal_df[['embedding', 'predicted_key', 'likelihoods']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of                                               embedding              labels  \\\n",
      "0     [0.37254903, 0.47843137, 0.5764706, 0.05490196...               [399]   \n",
      "1     [0.3137255, 0.70980394, 0.84705883, 0.6431373,...            [0, 451]   \n",
      "2     [0.41960785, 0.5882353, 0.34901962, 0.5411765,...           [27, 466]   \n",
      "3     [0.5529412, 0.3254902, 0.43137255, 0.69411767,...        [0, 95, 137]   \n",
      "4     [0.4, 0.18431373, 0.6666667, 0.23137255, 0.533...          [427, 431]   \n",
      "...                                                 ...                 ...   \n",
      "7966  [0.5647059, 0.6431373, 0.8039216, 0.4, 0.70980...             [0, 52]   \n",
      "7967  [0.26666668, 0.17254902, 0.8352941, 0.3882353,...             [0, 50]   \n",
      "7968  [0.34509805, 0.09803922, 0.654902, 0.39607844,...        [0, 26, 506]   \n",
      "7969  [0.6784314, 0.105882354, 0.49411765, 0.3725490...               [247]   \n",
      "7970  [0.7607843, 0.63529414, 0.9411765, 0.34117648,...  [27, 33, 137, 254]   \n",
      "\n",
      "     key predicted_key                                        likelihoods  \n",
      "0      C             A  [0.05636778845112223, 0.08669995534079632, 0.0...  \n",
      "1      C             A  [0.056948113012707996, 0.08381732069689841, 0....  \n",
      "2      C             A  [0.05644942824928668, 0.08634687890280632, 0.0...  \n",
      "3      C             F  [0.05771204558336973, 0.08250187840304446, 0.0...  \n",
      "4      C             A  [0.056701312957757065, 0.0845041332789606, 0.0...  \n",
      "...   ..           ...                                                ...  \n",
      "7966   C             A  [0.05722921414233082, 0.08258954176180248, 0.0...  \n",
      "7967   C             F  [0.05777232469083527, 0.08444126225086114, 0.0...  \n",
      "7968   C             A  [0.05708354872369149, 0.08470148040057272, 0.0...  \n",
      "7969   C             F  [0.05677326148562164, 0.08490096867845226, 0.0...  \n",
      "7970   C             A  [0.05777051606419753, 0.08620363965635092, 0.0...  \n",
      "\n",
      "[7971 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(bal_df.describe)\n",
    "x_train = bal_df.drop['likelihoods', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
