{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual Libraries USED FROM THE OTHER NOTEBOOK WE ADD MORE OR DELETE WHEN NECESSESARRY \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import distutils\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.github\\\\Data\\\\bal_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Specify the folder containing TFRecord files\u001b[39;00m\n\u001b[1;32m     75\u001b[0m tfrecord_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.github\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbal_train\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 76\u001b[0m tfrecord_files \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tfrecord_folder, f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(tfrecord_folder) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tfrecord\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Parse the TFRecords into a DataFrame\u001b[39;00m\n\u001b[1;32m     79\u001b[0m df \u001b[38;5;241m=\u001b[39m parse_tfrecords_to_dataframe(tfrecord_files)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.github\\\\Data\\\\bal_train'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Define the context features\n",
    "context_features = {\n",
    "    'video_id': tf.io.FixedLenFeature([], tf.string),\n",
    "    'start_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'end_time_seconds': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'labels': tf.io.VarLenFeature(tf.int64)\n",
    "}\n",
    "\n",
    "# Define the sequence features\n",
    "sequence_features = {\n",
    "    'audio_embedding': tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # Parse the example into context and sequence features\n",
    "    context_data, sequence_data = tf.io.parse_single_sequence_example(\n",
    "        example_proto,\n",
    "        context_features=context_features,\n",
    "        sequence_features=sequence_features\n",
    "    )\n",
    "    \n",
    "    # Decode the audio embeddings from the byte strings\n",
    "    audio_embeddings = tf.io.decode_raw(sequence_data['audio_embedding'].values, tf.uint8)\n",
    "    audio_embeddings = tf.reshape(audio_embeddings, [-1, 128])  # Reshape to [time_steps, embedding_size]\n",
    "    \n",
    "    # Normalize the embeddings to the range [0, 1]\n",
    "    audio_embeddings = tf.cast(audio_embeddings, tf.float32) / 255.0\n",
    "    \n",
    "    # Flatten the embedding to a 1D array\n",
    "    flattened_embedding = tf.reshape(audio_embeddings, [-1])\n",
    "    \n",
    "    # Convert sparse labels to dense\n",
    "    labels = tf.sparse.to_dense(context_data['labels'])\n",
    "    \n",
    "    return flattened_embedding, labels\n",
    "\n",
    "def parse_tfrecords_to_dataframe(tfrecord_files):\n",
    "    # Initialize an empty list to store embeddings and labels\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Iterate through each TFRecord file in the folder\n",
    "    for tfrecord_file in tqdm(tfrecord_files, desc=\"Processing TFRecord files\"):\n",
    "        raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "        parsed_dataset = raw_dataset.map(_parse_function)\n",
    "\n",
    "        # Iterate over the parsed dataset and collect embeddings and labels\n",
    "        for audio_embedding, labels in parsed_dataset:\n",
    "            # Convert to numpy arrays\n",
    "            audio_embedding_np = audio_embedding.numpy()\n",
    "            labels_np = labels.numpy()\n",
    "\n",
    "            # Flatten the label array if necessary\n",
    "            labels_np = labels_np.flatten() if len(labels_np.shape) > 0 else labels_np\n",
    "\n",
    "            # Store the embedding and label\n",
    "            embeddings_list.append(audio_embedding_np)\n",
    "            labels_list.append(labels_np)\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame({\n",
    "        'embedding': embeddings_list,\n",
    "        'labels': labels_list\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Specify the folder containing TFRecord files\n",
    "tfrecord_folder = '.github\\Data\\\\bal_train'\n",
    "tfrecord_files = [os.path.join(tfrecord_folder, f) for f in os.listdir(tfrecord_folder) if f.endswith('.tfrecord')]\n",
    "\n",
    "# Parse the TFRecords into a DataFrame\n",
    "df = parse_tfrecords_to_dataframe(tfrecord_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                               embedding              labels\n",
       "0     [0.37254903, 0.47843137, 0.5764706, 0.05490196...               [399]\n",
       "1     [0.3137255, 0.70980394, 0.84705883, 0.6431373,...            [0, 451]\n",
       "2     [0.41960785, 0.5882353, 0.34901962, 0.5411765,...           [27, 466]\n",
       "3     [0.5529412, 0.3254902, 0.43137255, 0.69411767,...        [0, 95, 137]\n",
       "4     [0.4, 0.18431373, 0.6666667, 0.23137255, 0.533...          [427, 431]\n",
       "...                                                 ...                 ...\n",
       "7966  [0.5647059, 0.6431373, 0.8039216, 0.4, 0.70980...             [0, 52]\n",
       "7967  [0.26666668, 0.17254902, 0.8352941, 0.3882353,...             [0, 50]\n",
       "7968  [0.34509805, 0.09803922, 0.654902, 0.39607844,...        [0, 26, 506]\n",
       "7969  [0.6784314, 0.105882354, 0.49411765, 0.3725490...               [247]\n",
       "7970  [0.7607843, 0.63529414, 0.9411765, 0.34117648,...  [27, 33, 137, 254]\n",
       "\n",
       "[7971 rows x 2 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape them  embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters (adjust as necessary)\n",
    "embedding_length = 128  # This should match the original dimension of each heatmap slice\n",
    "sequence_length = 100  # Adjust to match the desired number of time steps per sequence\n",
    "\n",
    "# Convert the embedding column to a numpy array and reshape each embedding\n",
    "def reshape_embeddings(df, embedding_length, sequence_length):\n",
    "    reshaped_embeddings = []\n",
    "    for embedding in df['embedding']:\n",
    "        # Ensure embedding is a numpy array\n",
    "        embedding = np.array(embedding)\n",
    "        \n",
    "        # Reshape the embedding into (sequence_length, embedding_length)\n",
    "        # If necessary, truncate or pad to the sequence_length\n",
    "        if len(embedding) < sequence_length * embedding_length:\n",
    "            # Pad with zeros if too short\n",
    "            padding_length = sequence_length * embedding_length - len(embedding)\n",
    "            embedding = np.pad(embedding, (0, padding_length), mode='constant')\n",
    "        elif len(embedding) > sequence_length * embedding_length:\n",
    "            # Truncate if too long\n",
    "            embedding = embedding[:sequence_length * embedding_length]\n",
    "        \n",
    "        # Reshape to (sequence_length, embedding_length)\n",
    "        embedding = embedding.reshape((sequence_length, embedding_length))\n",
    "        reshaped_embeddings.append(embedding)\n",
    "\n",
    "    # Convert to numpy array for model input\n",
    "    reshaped_embeddings = np.array(reshaped_embeddings)\n",
    "    return reshaped_embeddings\n",
    "\n",
    "# Apply reshaping to embeddings\n",
    "reshaped_embeddings = reshape_embeddings(df, embedding_length, sequence_length)\n",
    "\n",
    "# Output the reshaped array's shape to verify\n",
    "print(\"Reshaped Embeddings Shape:\", reshaped_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
